{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0a53fa80-1ed8-4e62-bd4a-016b7c5af69b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import*\n",
    "from pyspark.sql.types import StructType,StructField, StringType, IntegerType,LongType\n",
    "from pyspark.sql.functions import row_number,rank,dense_rank\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.functions import current_date,date_format,to_date,datediff,months_between,add_months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "433ee1d3-2325-4622-afd4-0d97e46f927b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>Bank</th><th>Address</th><th>AccountNumber</th></tr></thead><tbody><tr><td>HDFC</td><td>Chennai</td><td>1050010123940000</td></tr><tr><td>CANARA</td><td>Bangalore</td><td>2050010123940001</td></tr><tr><td>INDIAN</td><td>Hyderabad</td><td>3050010123940002</td></tr><tr><td>UNION</td><td>Mumbai</td><td>4050010123940003</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "HDFC",
         "Chennai",
         1050010123940000
        ],
        [
         "CANARA",
         "Bangalore",
         2050010123940001
        ],
        [
         "INDIAN",
         "Hyderabad",
         3050010123940002
        ],
        [
         "UNION",
         "Mumbai",
         4050010123940003
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "Bank",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Address",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "AccountNumber",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data=[(\"HDFC\",\"Chennai\",1050010123940000),\n",
    "      (\"CANARA\",\"Bangalore\",2050010123940001),\n",
    "      (\"INDIAN\",\"Hyderabad\",3050010123940002),\n",
    "      (\"UNION\",\"Mumbai\",4050010123940003)]\n",
    "\n",
    "schema=StructType([\n",
    "    StructField(\"Bank\",StringType()),\n",
    "    StructField(\"Address\",StringType()),\n",
    "    StructField(\"AccountNumber\",LongType())\n",
    "])\n",
    "\n",
    "df=spark.createDataFrame(data=data,schema=schema)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ac1886ba-acb7-488a-95e7-fead68fbc2bd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>Bank</th><th>Address</th><th>AccountNumber</th><th>AccountNumberStared</th></tr></thead><tbody><tr><td>HDFC</td><td>Chennai</td><td>1050010123940000</td><td>************0000</td></tr><tr><td>CANARA</td><td>Bangalore</td><td>2050010123940001</td><td>************0001</td></tr><tr><td>INDIAN</td><td>Hyderabad</td><td>3050010123940002</td><td>************0002</td></tr><tr><td>UNION</td><td>Mumbai</td><td>4050010123940003</td><td>************0003</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "HDFC",
         "Chennai",
         1050010123940000,
         "************0000"
        ],
        [
         "CANARA",
         "Bangalore",
         2050010123940001,
         "************0001"
        ],
        [
         "INDIAN",
         "Hyderabad",
         3050010123940002,
         "************0002"
        ],
        [
         "UNION",
         "Mumbai",
         4050010123940003,
         "************0003"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "Bank",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Address",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "AccountNumber",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "AccountNumberStared",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "star_df = df.withColumn(\"AccountNumberStared\",concat(lit('*' * 12),substring(col(\"AccountNumber\").cast(\"string\"), -4, 4)))\n",
    "display(star_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e6ff882c-136b-46ec-a57b-b7cc2245a7f4",
     "showTitle": true,
     "title": "splitting single column values into multiple rows"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------------------+\n|Col1                                                                      |\n+--------------------------------------------------------------------------+\n|1001|Ram|28|Java|1002|Raj|24|Database|1004|Jam|28|DotNet|1005|Kesh|25|Java|\n+--------------------------------------------------------------------------+\n\n"
     ]
    }
   ],
   "source": [
    "df=spark.read.format(\"csv\").option(\"header\", \"false\").load(\"dbfs:/FileStore/sample12__1_.csv\")\n",
    "df1=df.toDF(\"Col1\")\n",
    "df1.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "436b7053-ebc0-45f5-b5aa-0ff76395cb79",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------------------------+\n|Col2                                                                            |\n+--------------------------------------------------------------------------------+\n|1001|Ram|28|Java|\\n1002|Raj|24|Database|\\n1004|Jam|28|DotNet|\\n1005|Kesh|25|Java|\n+--------------------------------------------------------------------------------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as f\n",
    "df2=df1.withColumn('Col2',f.regexp_replace(f.col(\"Col1\"),\"(.*?\\\\|){4}\",\"$0\\n\"))\n",
    "df2.select(\"Col2\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "142dca46-b9dc-46b1-b84c-58a6522efd86",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+---+--------+\n| eno|ename|age|    tech|\n+----+-----+---+--------+\n|1001|  Ram| 28|    Java|\n|1002|  Raj| 24|Database|\n|1004|  Jam| 28|  DotNet|\n|1005| Kesh| 25|    Java|\n+----+-----+---+--------+\n\n"
     ]
    }
   ],
   "source": [
    "df_header=['eno','ename','age','tech']\n",
    "df2.select(f.explode(f.split(\"Col2\",\"\\n\")))\\\n",
    "    .select(f.split(\"col\",\"\\|\").alias(\"value\"))\\\n",
    "    .select(*map(lambda i: f.col(\"value\").getItem(df_header.index(i)).alias(i),df_header)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "51fee640-2a87-4a02-b671-3fc1ee19fbcd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+---+--------+\n| eno|ename|age|    tech|\n+----+-----+---+--------+\n|1001|  Ram| 28|    Java|\n|1002|  Raj| 24|Database|\n|1004|  Jam| 28|  DotNet|\n|1005| Kesh| 25|    Java|\n+----+-----+---+--------+\n\n"
     ]
    }
   ],
   "source": [
    "df_header=['eno','ename','age','tech']\n",
    "df2.select(f.explode(f.split(\"Col2\",\"\\n\")))\\\n",
    "    .select(f.split(\"col\",\"\\|\").alias(\"value\"))\\\n",
    "    .select(*map(lambda i: f.col(\"value\").getItem(df_header.index(i)).alias(i),df_header)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2e45cf30-a90d-46d5-825d-354185688a3f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------------------------------------------+\n|split(Col2, \\n, -1)                                                               |\n+----------------------------------------------------------------------------------+\n|[1001|Ram|28|Java|, 1002|Raj|24|Database|, 1004|Jam|28|DotNet|, 1005|Kesh|25|Java]|\n+----------------------------------------------------------------------------------+\n\n+---------------------+\n|col                  |\n+---------------------+\n|1001|Ram|28|Java|    |\n|1002|Raj|24|Database||\n|1004|Jam|28|DotNet|  |\n|1005|Kesh|25|Java    |\n+---------------------+\n\n+---------------------------+\n|value                      |\n+---------------------------+\n|[1001, Ram, 28, Java, ]    |\n|[1002, Raj, 24, Database, ]|\n|[1004, Jam, 28, DotNet, ]  |\n|[1005, Kesh, 25, Java]     |\n+---------------------------+\n\n"
     ]
    }
   ],
   "source": [
    "df_header=['eno','ename','age','tech']\n",
    "df2.select(f.split(\"Col2\",\"\\n\")).show(truncate=False)\n",
    "df2.select(f.explode(f.split(\"Col2\",\"\\n\"))).show(truncate=False)\n",
    "df2.select(f.explode(f.split(\"Col2\",\"\\n\")))\\\n",
    "    .select(f.split(\"col\",\"\\|\").alias(\"value\")).show(truncate=False)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "practice_ 2024-01-02",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
