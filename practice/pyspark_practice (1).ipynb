{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "89e8d1ea-a43a-4125-b3a2-68a179855a12",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import*\n",
    "from pyspark.sql.types import StructType,StructField, StringType, IntegerType,LongType\n",
    "from pyspark.sql.functions import row_number,rank,dense_rank\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.functions import current_date,date_format,to_date,datediff,months_between,add_months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "67491c2b-4e20-4df5-beaa-5318dac054b9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>Bank</th><th>Address</th><th>AccountNumber</th></tr></thead><tbody><tr><td>HDFC</td><td>Chennai</td><td>1050010123940000</td></tr><tr><td>CANARA</td><td>Bangalore</td><td>2050010123940001</td></tr><tr><td>INDIAN</td><td>Hyderabad</td><td>3050010123940002</td></tr><tr><td>UNION</td><td>Mumbai</td><td>4050010123940003</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "HDFC",
         "Chennai",
         1050010123940000
        ],
        [
         "CANARA",
         "Bangalore",
         2050010123940001
        ],
        [
         "INDIAN",
         "Hyderabad",
         3050010123940002
        ],
        [
         "UNION",
         "Mumbai",
         4050010123940003
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "Bank",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Address",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "AccountNumber",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data=[(\"HDFC\",\"Chennai\",1050010123940000),\n",
    "      (\"CANARA\",\"Bangalore\",2050010123940001),\n",
    "      (\"INDIAN\",\"Hyderabad\",3050010123940002),\n",
    "      (\"UNION\",\"Mumbai\",4050010123940003)]\n",
    "\n",
    "schema=StructType([\n",
    "    StructField(\"Bank\",StringType()),\n",
    "    StructField(\"Address\",StringType()),\n",
    "    StructField(\"AccountNumber\",LongType())\n",
    "])\n",
    "\n",
    "df=spark.createDataFrame(data=data,schema=schema)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8e821ab0-9b3a-4036-b7ff-4c3f9ef58c86",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>Bank</th><th>Address</th><th>AccountNumber</th><th>AccountNumberStared</th></tr></thead><tbody><tr><td>HDFC</td><td>Chennai</td><td>1050010123940000</td><td>************0000</td></tr><tr><td>CANARA</td><td>Bangalore</td><td>2050010123940001</td><td>************0001</td></tr><tr><td>INDIAN</td><td>Hyderabad</td><td>3050010123940002</td><td>************0002</td></tr><tr><td>UNION</td><td>Mumbai</td><td>4050010123940003</td><td>************0003</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "HDFC",
         "Chennai",
         1050010123940000,
         "************0000"
        ],
        [
         "CANARA",
         "Bangalore",
         2050010123940001,
         "************0001"
        ],
        [
         "INDIAN",
         "Hyderabad",
         3050010123940002,
         "************0002"
        ],
        [
         "UNION",
         "Mumbai",
         4050010123940003,
         "************0003"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "Bank",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Address",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "AccountNumber",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "AccountNumberStared",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "star_df = df.withColumn(\"AccountNumberStared\",concat(lit('*' * 12),substring(col(\"AccountNumber\").cast(\"string\"), -4, 4)))\n",
    "display(star_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e649e021-f03d-4d98-af26-4d5c0e8aea4a",
     "showTitle": true,
     "title": "rank(),dense_rank(),row_num()"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+---------+\n|  Name|    Dep|Salary|rownumber|\n+------+-------+------+---------+\n| Nancy|     HR|  2000|        1|\n| sowmi|     HR|  2500|        2|\n|Lishma|     HR|  3000|        3|\n|   raj|     IT|  1500|        1|\n|   Lav|     IT|  3000|        2|\n|   joe|     IT|  3000|        3|\n| rayan|     IT|  4000|        4|\n|Vishnu|PayRoll|  2000|        1|\n|  Diya|PayRoll|  2500|        2|\n+------+-------+------+---------+\n\n+------+-------+------+----+\n|  Name|    Dep|Salary|rank|\n+------+-------+------+----+\n| Nancy|     HR|  2000|   1|\n| sowmi|     HR|  2500|   2|\n|Lishma|     HR|  3000|   3|\n|   raj|     IT|  1500|   1|\n|   Lav|     IT|  3000|   2|\n|   joe|     IT|  3000|   2|\n| rayan|     IT|  4000|   4|\n|Vishnu|PayRoll|  2000|   1|\n|  Diya|PayRoll|  2500|   2|\n+------+-------+------+----+\n\n+------+-------+------+---------+\n|  Name|    Dep|Salary|denserank|\n+------+-------+------+---------+\n| Nancy|     HR|  2000|        1|\n| sowmi|     HR|  2500|        2|\n|Lishma|     HR|  3000|        3|\n|   raj|     IT|  1500|        1|\n|   Lav|     IT|  3000|        2|\n|   joe|     IT|  3000|        2|\n| rayan|     IT|  4000|        3|\n|Vishnu|PayRoll|  2000|        1|\n|  Diya|PayRoll|  2500|        2|\n+------+-------+------+---------+\n\n"
     ]
    }
   ],
   "source": [
    "data=[(\"Nancy\",\"HR\",2000),\n",
    "      (\"Lishma\",\"HR\",3000),\n",
    "      (\"Lav\",\"IT\",3000),\n",
    "      (\"sowmi\",\"HR\",2500),\n",
    "      (\"joe\",\"IT\",3000),\n",
    "      (\"raj\",\"IT\",1500),\n",
    "      (\"rayan\",\"IT\",4000),\n",
    "      (\"Diya\",\"PayRoll\",2500),\n",
    "      (\"Vishnu\",\"PayRoll\",2000)]\n",
    "schema=StructType([\n",
    "    StructField(\"Name\",StringType()),\n",
    "    StructField(\"Dep\",StringType()),\n",
    "    StructField(\"Salary\",IntegerType())\n",
    "])\n",
    "df=spark.createDataFrame(data=data,schema=schema)\n",
    "# df.show()\n",
    "# df.sort(\"Dep\").show()\n",
    "window=Window.partitionBy(\"Dep\").orderBy(\"Salary\")\n",
    "df.withColumn(\"rownumber\",row_number().over(window)).show()\n",
    "df.withColumn(\"rank\",rank().over(window)).show()\n",
    "df.withColumn(\"denserank\",dense_rank().over(window)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a19cf6e2-586a-46ac-847b-23a4dc7954c0",
     "showTitle": true,
     "title": "udf"
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>ID</th><th>Name</th><th>Salary</th><th>Bonus</th></tr></thead><tbody><tr><td>1</td><td>Nancy</td><td>2000</td><td>500</td></tr><tr><td>2</td><td>lish</td><td>3000</td><td>1000</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         1,
         "Nancy",
         2000,
         500
        ],
        [
         2,
         "lish",
         3000,
         1000
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "ID",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "Name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Salary",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "Bonus",
         "type": "\"integer\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = [(1,\"Nancy\",2000,500),\n",
    "        (2,\"lish\",3000,1000)]\n",
    "schema = StructType([\n",
    "    StructField(\"ID\",IntegerType()),\n",
    "    StructField(\"Name\",StringType()),\n",
    "    StructField(\"Salary\",IntegerType()),\n",
    "    StructField(\"Bonus\",IntegerType())    \n",
    "])\n",
    "df=spark.createDataFrame(data=data,schema=schema)\n",
    "df.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0c57eeb6-e6e7-4eab-b3db-1a466233e0e5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+------+-----+--------+\n| ID| Name|Salary|Bonus|totalpay|\n+---+-----+------+-----+--------+\n|  1|Nancy|  2000|  500|    2500|\n|  2| lish|  3000| 1000|    4000|\n+---+-----+------+-----+--------+\n\n"
     ]
    }
   ],
   "source": [
    "def totalpay(s,b):\n",
    "    return s+b \n",
    "# help(udf)\n",
    "TotalPayment = udf(lambda s,b : totalpay(s,b),IntegerType())\n",
    "df.withColumn(\"totalpay\",TotalPayment(df.Salary,df.Bonus)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c71832ef-1a4a-40f9-8584-67b6f172cef0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "data = [(1,\"Nancy\",2000,500),\n",
    "        (2,\"lish\",3000,1000)]\n",
    "schema = StructType([\n",
    "    StructField(\"ID\",IntegerType()),\n",
    "    StructField(\"Name\",StringType()),\n",
    "    StructField(\"Salary\",IntegerType()),\n",
    "    StructField(\"Bonus\",IntegerType())    \n",
    "])\n",
    "df=spark.createDataFrame(data,schema)\n",
    "df.createOrReplaceTempView('emp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "85a28e9b-065e-4f72-94b6-89dbf33fbae8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>ID</th><th>Name</th><th>Salary</th><th>Bonus</th></tr></thead><tbody><tr><td>1</td><td>Nancy</td><td>2000</td><td>500</td></tr><tr><td>2</td><td>lish</td><td>3000</td><td>1000</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         1,
         "Nancy",
         2000,
         500
        ],
        [
         2,
         "lish",
         3000,
         1000
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "ID",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "Name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Salary",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "Bonus",
         "type": "\"integer\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "select * from emp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9036e44b-2b78-4f8f-8977-f07568a5a5c6",
     "showTitle": true,
     "title": "date functions"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------+\n| id|currentdate|\n+---+-----------+\n|  0| 2024-01-02|\n|  1| 2024-01-02|\n+---+-----------+\n\n+---+-----------+\n| id|currentdate|\n+---+-----------+\n|  0| 2024-01-02|\n|  1| 2024-01-02|\n+---+-----------+\n\n"
     ]
    }
   ],
   "source": [
    "df=spark.range(2)\n",
    "df1 = df.withColumn(\"currentdate\",current_date())\n",
    "df1.show()\n",
    "df2=df1.withColumn(\"currentdate\",to_date(df1.currentdate,'yyyy-dd-mm'))\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4084fa07-fd96-4961-855f-cbcb5265c2c0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+\n|        d1|        d2|\n+----------+----------+\n|2023-11-20|2023-12-20|\n+----------+----------+\n\n+----------+----------+--------+\n|        d1|        d2|datediff|\n+----------+----------+--------+\n|2023-11-20|2023-12-20|      30|\n+----------+----------+--------+\n\n+----------+----------+-------------+\n|        d1|        d2|monthsbetween|\n+----------+----------+-------------+\n|2023-11-20|2023-12-20|          1.0|\n+----------+----------+-------------+\n\n+----------+----------+----------+\n|        d1|        d2| addmonths|\n+----------+----------+----------+\n|2023-11-20|2023-12-20|2024-10-20|\n+----------+----------+----------+\n\n+----------+----------+----------+\n|        d1|        d2|  submonth|\n+----------+----------+----------+\n|2023-11-20|2023-12-20|2023-09-20|\n+----------+----------+----------+\n\n"
     ]
    }
   ],
   "source": [
    "df=spark.createDataFrame([('2023-11-20','2023-12-20')], ['d1' ,'d2'])\n",
    "df.show()\n",
    "df.withColumn(\"datediff\",datediff(df.d2,df.d1)).show()\n",
    "df.withColumn('monthsbetween',months_between(df.d2,df.d1)).show()\n",
    "df.withColumn('addmonths',add_months(df.d2 , 10)).show()\n",
    "df.withColumn('submonth',add_months(df.d2 , -3)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3761af0b-30da-4c2e-9d27-e25088bcd017",
     "showTitle": true,
     "title": "map type"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Mohamed', 'Rayan', 'MohamedRayan'), ('Mohamed', 'Iayan', 'MohamedIayan')]\n"
     ]
    }
   ],
   "source": [
    "data = [('Mohamed','Rayan'),('Mohamed','Iayan')]\n",
    "rdd=spark.sparkContext.parallelize(data)\n",
    "rdd1 = rdd.map(lambda x : x + (x[0]+''+x[1],))\n",
    "print(rdd1.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dba48f5a-5e4e-42c2-bf16-0ec3162d2915",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+------------+\n|firstname|lastname|    fullname|\n+---------+--------+------------+\n|  Mohamed|   Rayan|MohamedRayan|\n|  Mohamed|   Iayan|MohamedIayan|\n+---------+--------+------------+\n\n"
     ]
    }
   ],
   "source": [
    "data = [('Mohamed','Rayan'),('Mohamed','Iayan')]\n",
    "df = spark.createDataFrame(data,['firstname','lastname'])\n",
    "rdd1 = df.rdd.map(lambda x : x + (x[0]+''+x[1],))\n",
    "df1 = rdd1.toDF(['firstname','lastname','fullname'])\n",
    "df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a2e061e1-f8d3-4d7c-aa5e-2e1464f9146b",
     "showTitle": true,
     "title": "In function"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+------------+\n|firstname|lastname|    fullname|\n+---------+--------+------------+\n|  Mohamed|   Rayan|MohamedRayan|\n|  Mohamed|   Iayan|MohamedIayan|\n+---------+--------+------------+\n\n"
     ]
    }
   ],
   "source": [
    "def fullname(x):\n",
    "    return x + (x[0]+''+x[1],)\n",
    "\n",
    "data = [('Mohamed','Rayan'),('Mohamed','Iayan')]\n",
    "df = spark.createDataFrame(data,['firstname','lastname'])\n",
    "rdd1 = df.rdd.map(lambda x : fullname(x))\n",
    "df1 = rdd1.toDF(['firstname','lastname','fullname'])\n",
    "df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c9aafb24-4b56-47dc-b0b9-e08ef91cc27f",
     "showTitle": true,
     "title": "split array element into separate column"
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>key</th><th>value</th></tr></thead><tbody><tr><td>ABC</td><td>List(1, 2, 3)</td></tr><tr><td>XYZ</td><td>List(2, null, 4)</td></tr><tr><td>KLM</td><td>List(8, 7)</td></tr><tr><td>IJK</td><td>List(5)</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "ABC",
         [
          1,
          2,
          3
         ]
        ],
        [
         "XYZ",
         [
          2,
          null,
          4
         ]
        ],
        [
         "KLM",
         [
          8,
          7
         ]
        ],
        [
         "IJK",
         [
          5
         ]
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "key",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "value",
         "type": "{\"type\":\"array\",\"elementType\":\"long\",\"containsNull\":true}"
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = spark.createDataFrame(sc.parallelize([['ABC',[1,2,3]],['XYZ',[2,None,4]],['KLM',[8,7]],['IJK',[5]]]),[\"key\",\"value\"])\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "31f671f6-874b-4325-8077-06825140688b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>key</th><th>value[0]</th><th>value[1]</th><th>value[2]</th></tr></thead><tbody><tr><td>ABC</td><td>1</td><td>2</td><td>3</td></tr><tr><td>XYZ</td><td>2</td><td>null</td><td>4</td></tr><tr><td>KLM</td><td>8</td><td>7</td><td>null</td></tr><tr><td>IJK</td><td>5</td><td>null</td><td>null</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "ABC",
         1,
         2,
         3
        ],
        [
         "XYZ",
         2,
         null,
         4
        ],
        [
         "KLM",
         8,
         7,
         null
        ],
        [
         "IJK",
         5,
         null,
         null
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "key",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "value[0]",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "value[1]",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "value[2]",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.select(\"key\",df.value[0],df.value[1],df.value[2]).display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1581193d-2095-48b2-9a86-c62940470507",
     "showTitle": true,
     "title": "Dynamic way"
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>key</th><th>value</th><th>NoofArrayElements</th></tr></thead><tbody><tr><td>ABC</td><td>List(1, 2, 3)</td><td>3</td></tr><tr><td>XYZ</td><td>List(2, null, 4)</td><td>3</td></tr><tr><td>KLM</td><td>List(8, 7)</td><td>2</td></tr><tr><td>IJK</td><td>List(5)</td><td>1</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "ABC",
         [
          1,
          2,
          3
         ],
         3
        ],
        [
         "XYZ",
         [
          2,
          null,
          4
         ],
         3
        ],
        [
         "KLM",
         [
          8,
          7
         ],
         2
        ],
        [
         "IJK",
         [
          5
         ],
         1
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "key",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "value",
         "type": "{\"type\":\"array\",\"elementType\":\"long\",\"containsNull\":true}"
        },
        {
         "metadata": "{}",
         "name": "NoofArrayElements",
         "type": "\"integer\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql.functions import size,col\n",
    "dfSize = df.select(\"key\",\"value\",size(\"value\").alias(\"NoofArrayElements\"))\n",
    "dfSize.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3715a66a-9aee-4e4c-8f53-27eb415d136c",
     "showTitle": true,
     "title": "Get the maximum size of all array"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "max_value = dfSize.agg({\"NoofArrayElements\":\"max\"}).collect()[0][0]\n",
    "print(max_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "539c17ed-ea4c-462b-9e65-a3a9f35ca757",
     "showTitle": true,
     "title": "Udf to convert array elements into columns"
    }
   },
   "outputs": [],
   "source": [
    "def arraySplitIntoCols(df,maxElements):\n",
    "    for i in range(maxElements):\n",
    "        df = df.withColumn(f\"new_col{i}\",df.value[i])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cfe3f242-f85d-4b0d-97e4-b87e7ab9ff80",
     "showTitle": true,
     "title": "Udf call"
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>key</th><th>value</th><th>new_col0</th><th>new_col1</th><th>new_col2</th></tr></thead><tbody><tr><td>ABC</td><td>List(1, 2, 3)</td><td>1</td><td>2</td><td>3</td></tr><tr><td>XYZ</td><td>List(2, null, 4)</td><td>2</td><td>null</td><td>4</td></tr><tr><td>KLM</td><td>List(8, 7)</td><td>8</td><td>7</td><td>null</td></tr><tr><td>IJK</td><td>List(5)</td><td>5</td><td>null</td><td>null</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "ABC",
         [
          1,
          2,
          3
         ],
         1,
         2,
         3
        ],
        [
         "XYZ",
         [
          2,
          null,
          4
         ],
         2,
         null,
         4
        ],
        [
         "KLM",
         [
          8,
          7
         ],
         8,
         7,
         null
        ],
        [
         "IJK",
         [
          5
         ],
         5,
         null,
         null
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "key",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "value",
         "type": "{\"type\":\"array\",\"elementType\":\"long\",\"containsNull\":true}"
        },
        {
         "metadata": "{}",
         "name": "new_col0",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "new_col1",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "new_col2",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dfout = arraySplitIntoCols(df,max_value)\n",
    "display(dfout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "26fca14d-8f95-49db-b30b-7cfd60f0f788",
     "showTitle": true,
     "title": "splitting single column values into multiple rows"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------------------+\n|Col1                                                                      |\n+--------------------------------------------------------------------------+\n|1001|Ram|28|Java|1002|Raj|24|Database|1004|Jam|28|DotNet|1005|Kesh|25|Java|\n+--------------------------------------------------------------------------+\n\n"
     ]
    }
   ],
   "source": [
    "df=spark.read.format(\"csv\").option(\"header\", \"false\").load(\"dbfs:/FileStore/sample12__1_.csv\")\n",
    "df1=df.toDF(\"Col1\")\n",
    "df1.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a5c98850-bb1b-42aa-8978-d3446a27af97",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------------------------+\n|Col2                                                                            |\n+--------------------------------------------------------------------------------+\n|1001|Ram|28|Java|\\n1002|Raj|24|Database|\\n1004|Jam|28|DotNet|\\n1005|Kesh|25|Java|\n+--------------------------------------------------------------------------------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as f\n",
    "df2=df1.withColumn('Col2',f.regexp_replace(f.col(\"Col1\"),\"(.*?\\\\|){4}\",\"$0\\n\"))\n",
    "df2.select(\"Col2\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ac9dd902-3094-434f-a524-f659af76c80b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+---+--------+\n| eno|ename|age|    tech|\n+----+-----+---+--------+\n|1001|  Ram| 28|    Java|\n|1002|  Raj| 24|Database|\n|1004|  Jam| 28|  DotNet|\n|1005| Kesh| 25|    Java|\n+----+-----+---+--------+\n\n"
     ]
    }
   ],
   "source": [
    "df_header=['eno','ename','age','tech']\n",
    "df2.select(f.explode(f.split(\"Col2\",\"\\n\")))\\\n",
    "    .select(f.split(\"col\",\"\\|\").alias(\"value\"))\\\n",
    "    .select(*map(lambda i: f.col(\"value\").getItem(df_header.index(i)).alias(i),df_header)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "30edb5e1-a3a0-49b4-844c-1dd6c6700b93",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+---+--------+\n| eno|ename|age|    tech|\n+----+-----+---+--------+\n|1001|  Ram| 28|    Java|\n|1002|  Raj| 24|Database|\n|1004|  Jam| 28|  DotNet|\n|1005| Kesh| 25|    Java|\n+----+-----+---+--------+\n\n"
     ]
    }
   ],
   "source": [
    "df_header=['eno','ename','age','tech']\n",
    "df2.select(f.explode(f.split(\"Col2\",\"\\n\")))\\\n",
    "    .select(f.split(\"col\",\"\\|\").alias(\"value\"))\\\n",
    "    .select(*map(lambda i: f.col(\"value\").getItem(df_header.index(i)).alias(i),df_header)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bd7e837b-0129-43ae-858d-c12cd2d8efe5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------------------------------------------+\n|split(Col2, \\n, -1)                                                               |\n+----------------------------------------------------------------------------------+\n|[1001|Ram|28|Java|, 1002|Raj|24|Database|, 1004|Jam|28|DotNet|, 1005|Kesh|25|Java]|\n+----------------------------------------------------------------------------------+\n\n+---------------------+\n|col                  |\n+---------------------+\n|1001|Ram|28|Java|    |\n|1002|Raj|24|Database||\n|1004|Jam|28|DotNet|  |\n|1005|Kesh|25|Java    |\n+---------------------+\n\n+---------------------------+\n|value                      |\n+---------------------------+\n|[1001, Ram, 28, Java, ]    |\n|[1002, Raj, 24, Database, ]|\n|[1004, Jam, 28, DotNet, ]  |\n|[1005, Kesh, 25, Java]     |\n+---------------------------+\n\n"
     ]
    }
   ],
   "source": [
    "df_header=['eno','ename','age','tech']\n",
    "df2.select(f.split(\"Col2\",\"\\n\")).show(truncate=False)\n",
    "df2.select(f.explode(f.split(\"Col2\",\"\\n\"))).show(truncate=False)\n",
    "df2.select(f.explode(f.split(\"Col2\",\"\\n\")))\\\n",
    "    .select(f.split(\"col\",\"\\|\").alias(\"value\")).show(truncate=False)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 4347718197022291,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "pyspark_practice",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
